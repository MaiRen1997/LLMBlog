## 开发工具函数

```python
def add(a, b):
    return a + b
```

## 将工具函数转为LangChain Tool对象

### 概述

LangChain中的工具（Tool）是一个封装了特定功能的类，它包含四个核心组成部分：

- 名称（name）：名称是工具在工具集合中的**唯一标识符**，必须确保在同一工具集中不重复
- 描述（description）：描述用于说明工具的功能，为LLM或代理提供上下文信息，**帮助模型理解何时以及如何调用该工具**
- 参数模式（args_schema）：是使用Pydantic BaseModel定义的输入参数结构，用于验证和解析工具调用的参数
- 是否直接返回（return_direct）：布尔值属性，当设置为True时，智能体会在调用工具后立即返回结果给用户，而不继续调用其他工具

```python
#common函数
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatMessagePromptTemplate, ChatPromptTemplate

llm = ChatOpenAI(
    model="qwen-max",
    # model="qwen3-235b-a22b",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=os.environ.get("BAILIAN_API_KEY"),
    streaming=True,
)
system_message_template = ChatMessagePromptTemplate.from_template(
    template="你是一位{role}专家，擅长回答{domain}领域的问题",
    role="system",
)


human_message_template = ChatMessagePromptTemplate.from_template(
    template="用户问题：{question}",
    role="user",
)
# 创建提示词模板
chat_prompt_template = ChatPromptTemplate.from_messages([
    system_message_template,
    human_message_template,
])
```



```python
from langchain_core.tools import tool
from pydantic import BaseModel
from app.bailian.common import chat_prompt_template, llm

class AddInputArgs(BaseModel):
    a: int = Field(description="first number") # 这里的 int 或者str，大模型会参考，然后决定是字符拼接，还是数字相加
    b: int = Field(description="second number")

@tool(
    description="add two numbers",
    args_schema=AddInputArgs, # 定义工具输入的类型
    return_direct=True,
)

def add(a, b):
    """add two numbers"""
    return a + b


tool_dict = {
    "add": add
}

llm_with_tools = llm.bind_tools([add])

chain = chat_prompt_template | llm_with_tools

resp = chain.invoke(input={"role": "计算", "domain": "数学计算", "question": "使用工具计算：100+100=?"})

print(resp)

for tool_calls in resp.tool_calls:
    print(tool_calls)

    args = tool_calls["args"]
    print(args)

    func_name = tool_calls["name"]
    print(func_name)

    tool_func = tool_dict[func_name]

    tool_content = tool_func.invoke(args)
    print(tool_content)

```

### 定义方法

1. 方法一：使用Tool.from_function生成

   ```python
   add_tools = Tool.from_function(
       func=add,
       name="add",
       description="计算两个数相加"
   )
   ```

2. 方法2：使用@tool装饰器生成

   ```python
   @tool
   def add(a, b):
       """add two numbers"""
       return a + b
   ```

## 将大模型和Tool对象绑定

```python
llm_with_tools = llm.bind_tools([add_tools])
```

## 调用大模型，尝试让大模型调用工具

1. 大模型不会调用工具
2. 大模型是解析工具函数吗，然后告诉我们如何调用工具

```python
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一名资深的开发工程师，叫做小慕"),
    ("human", "{user_input}"),
])

chain = prompt | llm_with_tools

response = chain.invoke({"user_input": "计算100+100"})
```

## 第五步：调用工具

根据大模型解析返回的Tools结果执行函数：

```python
for tool_calls in resp.tool_calls:
    print(tool_calls)

    args = tool_calls['args']
    func_name = tool_calls['name']

    func = tools_dict[func_name]
    tool_content = func.invoke(args)
    print(tool_content)
```













