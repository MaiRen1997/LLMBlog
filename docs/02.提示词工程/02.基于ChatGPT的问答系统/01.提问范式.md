---
title: 提问范式
date: 2026-02-04 17:29:12
permalink: /pages/964c89/
categories:
  - 提示词工程
  - 基于ChatGPT的问答系统
tags:
  - 
---
## LLM 的两种类型（了解大脑的运作方式）

文章首先区分了两种不同目标的语言模型，这决定了你选择什么样的 API。

1. 指令微调型 LLM (Instruction Tuned LLM) —— Agent 的首选
特点：经过专门训练，能够遵循指令、回答问题并进行对话。

训练过程：在基础模型之上，使用大量“指令-回复”数据集进行微调，并结合 RLHF（人类反馈强化学习）使其更安全、更有帮助。

适用场景：绝大多数 Agent 开发、任务执行、逻辑推理。

2. 基础 LLM (Base LLM)
特点：仅仅是根据海量数据预测“下一个词”。

缺点：如果你问“中国的首都是哪里？”，它可能会回复“法国的首都是巴黎”，因为它觉得你在写一份地理考卷列表。

适用场景：极少数特定微调场景，一般不直接用于 Agent。

##  核心计量单位：Token（理解模型的“词汇量”）

模型阅读的不是“单词”，而是 Token。这是开发 Agent 时计算成本（钱）和上下文长度限制（容量）的唯一标准。

1. Token 是什么？
转换规则：1 个 Token 大约相当于 4 个英文单词的字符，或者 0.75 个英文单词。对于中文，一个汉字通常占用 1 到 2 个 Token。

底层逻辑：模型将常见的字符组合（如 "learning"）拆分为 Token（如 "learn" + "ing"）。

2. Token 的重要局限
字母反转难题：由于模型看的是 Token 而不是单个字母，它在处理“将单词 lollipop 反转”这类任务时会表现很差。

初学者技巧：处理这类任务时，在字母间加连字符（l-o-l-l-i-p-o-p），强制模型看清每个字符。

上下文限制 (Context Window)：每个模型都有 Token 总量上限。如果对话记录超过上限，模型会“失忆”。

三、 提问范式：Chat Format（Agent 的通信协议）
这是对第一部分第 8 章“角色定义”的深度延伸，展示了如何通过结构化数据驱动 Agent。

1. 消息对象结构
API 接收的是一个包含多个消息对象的列表，每个对象必须包含 role 和 content。

System Message (系统消息)：

核心作用：设定 Agent 的“元指令”。它像是一道紧箍咒，规定了模型不能逾越的边界。

示例："你是一个只用中文回答的资深程序员。"

User Message (用户消息)：

作用：代表用户的具体需求。

Assistant Message (助手消息)：

作用：存储模型之前的回答。

2. 为什么 Assistant Message 也由开发者提供？
关键点：在多轮对话中，你需要手动把模型上一次的回答（Assistant 内容）重新发给模型，它才知道刚才聊了什么。

四、 对初学者的 Agent 开发启示
成本意识：写 Prompt 时，废话越多，消耗的 Token 越多，成本越高。

指令优先：在编写 Agent 逻辑时，尽量使用指令微调型模型（如 GPT-4, Claude 3），它们的逻辑遵循能力远超基础模型。

系统消息是 Agent 的“灵魂”：

如果你想让 Agent 表现得像个机器人，就在 System Message 里写：“你是一个无情的自动化脚本”。

如果你想让它表现得像个导师，就写：“请通过提问引导用户，不要直接给答案”。