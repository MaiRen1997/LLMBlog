(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{344:function(t,v,_){"use strict";_.r(v);var e=_(7),n=Object(e.a)({},(function(){var t=this,v=t._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[v("h2",{attrs:{id:"llm-的两种类型-了解大脑的运作方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#llm-的两种类型-了解大脑的运作方式"}},[t._v("#")]),t._v(" LLM 的两种类型（了解大脑的运作方式）")]),t._v(" "),v("p",[t._v("文章首先区分了两种不同目标的语言模型，这决定了你选择什么样的 API。")]),t._v(" "),v("ol",[v("li",[t._v("指令微调型 LLM (Instruction Tuned LLM) —— Agent 的首选\n特点：经过专门训练，能够遵循指令、回答问题并进行对话。")])]),t._v(" "),v("p",[t._v("训练过程：在基础模型之上，使用大量“指令-回复”数据集进行微调，并结合 RLHF（人类反馈强化学习）使其更安全、更有帮助。")]),t._v(" "),v("p",[t._v("适用场景：绝大多数 Agent 开发、任务执行、逻辑推理。")]),t._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[t._v("基础 LLM (Base LLM)\n特点：仅仅是根据海量数据预测“下一个词”。")])]),t._v(" "),v("p",[t._v("缺点：如果你问“中国的首都是哪里？”，它可能会回复“法国的首都是巴黎”，因为它觉得你在写一份地理考卷列表。")]),t._v(" "),v("p",[t._v("适用场景：极少数特定微调场景，一般不直接用于 Agent。")]),t._v(" "),v("h2",{attrs:{id:"核心计量单位-token-理解模型的-词汇量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#核心计量单位-token-理解模型的-词汇量"}},[t._v("#")]),t._v(" 核心计量单位：Token（理解模型的“词汇量”）")]),t._v(" "),v("p",[t._v("模型阅读的不是“单词”，而是 Token。这是开发 Agent 时计算成本（钱）和上下文长度限制（容量）的唯一标准。")]),t._v(" "),v("ol",[v("li",[t._v("Token 是什么？\n转换规则：1 个 Token 大约相当于 4 个英文单词的字符，或者 0.75 个英文单词。对于中文，一个汉字通常占用 1 到 2 个 Token。")])]),t._v(" "),v("p",[t._v('底层逻辑：模型将常见的字符组合（如 "learning"）拆分为 Token（如 "learn" + "ing"）。')]),t._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[t._v("Token 的重要局限\n字母反转难题：由于模型看的是 Token 而不是单个字母，它在处理“将单词 lollipop 反转”这类任务时会表现很差。")])]),t._v(" "),v("p",[t._v("初学者技巧：处理这类任务时，在字母间加连字符（l-o-l-l-i-p-o-p），强制模型看清每个字符。")]),t._v(" "),v("p",[t._v("上下文限制 (Context Window)：每个模型都有 Token 总量上限。如果对话记录超过上限，模型会“失忆”。")]),t._v(" "),v("p",[t._v("三、 提问范式：Chat Format（Agent 的通信协议）\n这是对第一部分第 8 章“角色定义”的深度延伸，展示了如何通过结构化数据驱动 Agent。")]),t._v(" "),v("ol",[v("li",[t._v("消息对象结构\nAPI 接收的是一个包含多个消息对象的列表，每个对象必须包含 role 和 content。")])]),t._v(" "),v("p",[t._v("System Message (系统消息)：")]),t._v(" "),v("p",[t._v("核心作用：设定 Agent 的“元指令”。它像是一道紧箍咒，规定了模型不能逾越的边界。")]),t._v(" "),v("p",[t._v('示例："你是一个只用中文回答的资深程序员。"')]),t._v(" "),v("p",[t._v("User Message (用户消息)：")]),t._v(" "),v("p",[t._v("作用：代表用户的具体需求。")]),t._v(" "),v("p",[t._v("Assistant Message (助手消息)：")]),t._v(" "),v("p",[t._v("作用：存储模型之前的回答。")]),t._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[t._v("为什么 Assistant Message 也由开发者提供？\n关键点：在多轮对话中，你需要手动把模型上一次的回答（Assistant 内容）重新发给模型，它才知道刚才聊了什么。")])]),t._v(" "),v("p",[t._v("四、 对初学者的 Agent 开发启示\n成本意识：写 Prompt 时，废话越多，消耗的 Token 越多，成本越高。")]),t._v(" "),v("p",[t._v("指令优先：在编写 Agent 逻辑时，尽量使用指令微调型模型（如 GPT-4, Claude 3），它们的逻辑遵循能力远超基础模型。")]),t._v(" "),v("p",[t._v("系统消息是 Agent 的“灵魂”：")]),t._v(" "),v("p",[t._v("如果你想让 Agent 表现得像个机器人，就在 System Message 里写：“你是一个无情的自动化脚本”。")]),t._v(" "),v("p",[t._v("如果你想让它表现得像个导师，就写：“请通过提问引导用户，不要直接给答案”。")])])}),[],!1,null,null,null);v.default=n.exports}}]);